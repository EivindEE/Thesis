% Chapter Template

\chapter{Introduction} % Main chapter title

\label{Introduction} % Change X to a consecutive number; for referencing this chapter elsewhere, 
use \ref{Introduction}

\lhead{Chapter \ref{Introduction}. \emph{Introduction}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1: Background
%----------------------------------------------------------------------------------------

\section{Background}
The internet is now an ingrained part of our everyday life, 
and the amount of content and services that are available through it is growing at an ever increasing rate. 
For all this information to be of use to humans it is necessary to have some interface through which to access the parts of it that are relevant to us. 
\citet{Shirky2007} tells of the early attempts to structure the web, 
using ontologies and hierarchies created by experts. 
This soon got clunky as the number of documents increased, 
and this way of organizing information fell out of favor to be replaced by searching for information using keywords. 
It is this phase of organizing information we are in now. 

\citet{Berners-Lee2001} suggested that we could do better than this. 
With searching as it works today users have to manually check the results from the search engine, 
and compare the results from several documents, following links as is necessary. 
Instead of forcing users to go through this process, 
this new idea was to enrich the documents we put on the web with meta data that could be read and reasoned about by computers. 
By doing this we could move the tedious task of siphoning though websites looking for relevant information from users 
over to specialized software agents that could collect information on the topic and return the answer to the user.

This does create some extra work for content creators on the internet.
Adding meta data to content is not a trivial task. 
Using RDFa allows the content creator to add arbitrary meta data, 
but requires knowledge both of which ontologies exists that contain the meaning the creator wants to convey,
and knowledge about how those ontologies are structured to use them in the correct way.


Ontology is the philosophical discipline of finding out which things exist, 
the maner in which one can say that these exist and how these can be categorized. 
When we talk about ontologies in the context of the semantic web, 
an ontology can be explained as the collection of the things that we can talk about using that language, 
and how these things relate to each other.

%----------------------------------------------------------------------------------------
%	SECTION 2: Motivation
%----------------------------------------------------------------------------------------

\section{Motivation}
At the moment, adding semantic markup to websites is unfeasible for most content creators on the web.
Adding proper meta data does not only mean that you need to know HTML, 
but also that you need to understand the concept of ontologies and set theory. 
In addition you need to know of the implementation of RDFa, microdata or microformats, 
as well as the content of the specific ontologies you intent to use on your site.


It is estimated that the amount of information created by humans before 2005, 

is smaller that the amount of information created after 2005.

I chose to develop using node.js because it's a new and exciting technology which would make it posible to write the entire app using one programming language for front end, 
server side and as the database query language.

Creating a web app allows me to work with both back end server side components, 
and front end work. 

%----------------------------------------------------------------------------------------
%	SECTION 3: Research Questions
%----------------------------------------------------------------------------------------

\section{Research Questions}
In this thesis I want to see if it is feasible to use WordNet synsets as an intermediary 
to find mappings from natural languages into formal ontologies using mapping files.
The thesis will look at different strategies for mapping synsets to ontologies. 
The strategies will try to balance finding mappings which are at an equal, 

or similar level of abstraction with having a low level of incorrect mappings.
In the cases where there are incorrect mappings, 

we will try to analyse the results to see if we can find the cause of the mistakes to see if they are caused by the 
mapping algorithms, 
or by incomplete or erroneous mappings.

We will also look at how the different strategies work when used in the wild, 
and see if the potential mistakes we find
in the previous section will create practical difficulties for the tool. 
The combination of these results should give us enough information to 
\subsection{Goals}

The tool should be able to:
\begin{itemize}
	\item Let users add meta data using natural language
	\item Let users disambiguate
	\item Create mappings into several existing ontologies
	\item Be flexible enough that new ontologies can be added
\end{itemize}

\subsection{Sub-questions}
Insert research sub-goals
